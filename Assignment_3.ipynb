{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ### Q1. In order to predict house price based on several characteristics, such as location, square footage, number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this situation would be the best to employ?\n",
    "\n",
    "# The most appropriate regression metric for predicting house prices accurately would be the **Mean Squared Error (MSE)**. MSE is a good measure of the average magnitude of errors in predictions without considering their direction. It is especially useful when you want to penalize larger errors more significantly, which is often the case in price prediction tasks.\n",
    "\n",
    "# ### Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?\n",
    "\n",
    "# If the goal is to predict the actual price of a house as accurately as possible, the **Mean Squared Error (MSE)** would be more appropriate. MSE directly measures the average squared difference between predicted and actual values, making it a better choice for accuracy in price prediction.\n",
    "\n",
    "# ### Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?\n",
    "\n",
    "# When dealing with a dataset with significant outliers, the **Mean Absolute Error (MAE)** is often more appropriate. MAE measures the average magnitude of errors in predictions without considering their direction and is less sensitive to outliers compared to MSE.\n",
    "\n",
    "# ### Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?\n",
    "\n",
    "# If MSE and RMSE values are very close, you can use either metric. However, **Root Mean Squared Error (RMSE)** might be preferred because it is in the same units as the target variable (e.g., dollars for house prices), making it more interpretable.\n",
    "\n",
    "# ### Q5. You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?\n",
    "\n",
    "# If the goal is to measure how well the model explains the variance in the target variable, **R-squared (R²)** is the most appropriate metric. R² indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "\n",
    "# ### Implementation of SVM Regression Model\n",
    "\n",
    "# Let's implement an SVM regression model using a dataset (link provided) and evaluate it using the appropriate metrics.\n",
    "\n",
    "# #### Step-by-Step Implementation\n",
    "\n",
    "# 1. **Import the necessary libraries and load the dataset**.\n",
    "# 2. **Split the dataset into training and testing sets**.\n",
    "# 3. **Preprocess the data**.\n",
    "# 4. **Create and train an SVM regression model**.\n",
    "# 5. **Evaluate the model using MSE, R², and other appropriate metrics**.\n",
    "# 6. **Tune the hyperparameters of the model**.\n",
    "# 7. **Save the trained model**.\n",
    "\n",
    "# Here is the Python code to accomplish these steps:\n",
    "\n",
    "# ```python\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import joblib\n",
    "\n",
    "# # Load the dataset\n",
    "# url = \"https://drive.google.com/uc?id=1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0\"\n",
    "# data = pd.read_csv(url)\n",
    "\n",
    "# # Display the first few rows of the dataset\n",
    "# print(data.head())\n",
    "\n",
    "# # Split the dataset into features and target variable\n",
    "# X = data.drop(columns=['Price'])\n",
    "# y = data['Price']\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Create and train an SVM regression model with a polynomial kernel\n",
    "# svr_poly = SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
    "# svr_poly.fit(X_train, y_train)\n",
    "\n",
    "# # Predict the target variable for the testing set\n",
    "# y_pred = svr_poly.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f'MSE: {mse:.2f}')\n",
    "# print(f'RMSE: {rmse:.2f}')\n",
    "# print(f'MAE: {mae:.2f}')\n",
    "# print(f'R-squared: {r2:.2f}')\n",
    "\n",
    "# # Tune the hyperparameters of the model using GridSearchCV\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'epsilon': [0.01, 0.1, 0.2, 0.5],\n",
    "#     'degree': [2, 3, 4]\n",
    "# }\n",
    "# grid_search = GridSearchCV(SVR(kernel='poly'), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and best score\n",
    "# print(f'Best parameters: {grid_search.best_params_}')\n",
    "# print(f'Best score: {grid_search.best_score_}')\n",
    "\n",
    "# # Train the tuned model on the entire dataset\n",
    "# best_svr = grid_search.best_estimator_\n",
    "# best_svr.fit(X_train, y_train)\n",
    "\n",
    "# # Save the trained model to a file\n",
    "# joblib.dump(best_svr, 'svr_poly_model.pkl')\n",
    "\n",
    "# # Predict and evaluate the tuned model\n",
    "# y_pred_tuned = best_svr.predict(X_test)\n",
    "# mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
    "# rmse_tuned = np.sqrt(mse_tuned)\n",
    "# mae_tuned = mean_absolute_error(y_test, y_pred_tuned)\n",
    "# r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "\n",
    "# print(f'Tuned MSE: {mse_tuned:.2f}')\n",
    "# print(f'Tuned RMSE: {rmse_tuned:.2f}')\n",
    "# print(f'Tuned MAE: {mae_tuned:.2f}')\n",
    "# print(f'Tuned R-squared: {r2_tuned:.2f}')\n",
    "# ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
